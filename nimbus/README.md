# Nimbus# Nimbus



> **A high-performance, production-ready event analytics platform built with modern async Python architecture.**> **A high-performance, production-ready event analytics platform built with modern async Python architecture.**



[![Python](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)[![Python](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)

[![FastAPI](https://img.shields.io/badge/FastAPI-0.115+-green.svg)](https://fastapi.tiangolo.com/)[![FastAPI](https://img.shields.io/badge/FastAPI-0.115+-green.svg)](https://fastapi.tiangolo.com/)

[![SQLAlchemy](https://img.shields.io/badge/SQLAlchemy-2.0+-red.svg)](https://www.sqlalchemy.org/)[![SQLAlchemy](https://img.shields.io/badge/SQLAlchemy-2.0+-red.svg)](https://www.sqlalchemy.org/)

[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15+-blue.svg)](https://www.postgresql.org/)[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15+-blue.svg)](https://www.postgresql.org/)

[![Tests](https://img.shields.io/badge/tests-passing-brightgreen.svg)]()[![Tests](https://img.shields.io/badge/tests-passing-brightgreen.svg)]()



## ğŸš€ Overview## ğŸš€ Overview



Nimbus is an enterprise-grade event ingestion and analytics API designed for high-throughput data collection and real-time metrics aggregation. Built with async-first principles, it provides millisecond-level event processing with horizontal scalability.Nimbus is an enterprise-grade event ingestion and analytics API designed for high-throughput data collection and real-time metrics aggregation. Built with async-first principles, it provides millisecond-level event processing with horizontal scalability.



### Key Features### Key Features



- **âš¡ Async Architecture** - Built on FastAPI + SQLAlchemy 2.0 async with asyncpg driver- **âš¡ Async Architecture** - Built on FastAPI + SQLAlchemy 2.0 async with asyncpg driver

- **ğŸ” Multi-layer Security** - JWT authentication, HMAC request signing, bcrypt password hashing- **ğŸ” Multi-layer Security** - JWT authentication, HMAC request signing, bcrypt password hashing

- **ğŸ“Š Real-time Analytics** - Time-series aggregation with configurable bucketing (1m, 5m, 15m, 1h, 1d)- **ğŸ“Š Real-time Analytics** - Time-series aggregation with configurable bucketing (1m, 5m, 15m, 1h, 1d)

- **ğŸ¯ Project Isolation** - Multi-tenant architecture with per-project API keys- **ğŸ¯ Project Isolation** - Multi-tenant architecture with per-project API keys

- **ğŸ’¾ Idempotent Ingestion** - Duplicate event detection via idempotency keys- **ğŸ’¾ Idempotent Ingestion** - Duplicate event detection via idempotency keys

- **ğŸ”„ Database Migrations** - Alembic-managed schema versioning- **ğŸ”„ Database Migrations** - Alembic-managed schema versioning

- **ğŸ“ˆ Production Ready** - Rate limiting, CORS, structured logging, health checks- **ğŸ“ˆ Production Ready** - Rate limiting, CORS, structured logging, health checks

- **ğŸ§ª Comprehensive Testing** - 100% test coverage with pytest-asyncio- **ğŸ§ª Comprehensive Testing** - 100% test coverage with pytest-asyncio

- **ğŸ³ Docker Support** - Full containerization with Docker Compose- **ğŸ³ Docker Support** - Full containerization with Docker Compose



## ğŸ“‹ Table of Contents## ğŸš€ Overview- **Design Patterns:**



- [Architecture](#-architecture)  - Dependency Injection (FastAPI `Depends`)

- [Technology Stack](#-technology-stack)

- [Getting Started](#-getting-started)Nimbus is an enterprise-grade event ingestion and analytics API designed for high-throughput data collection and real-time metrics aggregation. Built with async-first principles, it provides millisecond-level event processing with horizontal scalability.  - Repository pattern for DB access

- [API Documentation](#-api-documentation)

- [Database Schema](#-database-schema)  - Service layer for business logic

- [Security](#-security)

- [Configuration](#-configuration)### Key Features  - Pydantic schemas for validation

- [Development](#-development)

- [Testing](#-testing)  - Modular routing and separation of concerns

- [Deployment](#-deployment)

- [Performance](#-performance)- **âš¡ Async Architecture** - Built on FastAPI + SQLAlchemy 2.0 async with asyncpg driver- **Security:**



## ğŸ—ï¸ Architecture- **ğŸ” Multi-layer Security** - JWT authentication, HMAC request signing, bcrypt password hashing  - JWT for user authentication



```- **ğŸ“Š Real-time Analytics** - Time-series aggregation with configurable bucketing (1m, 5m, 15m, 1h, 1d)  - HMAC for event ingestion

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚                         Client Layer                         â”‚- **ğŸ¯ Project Isolation** - Multi-tenant architecture with per-project API keys  - Rate limiting (SlowAPI)

â”‚  (Web Apps, Mobile Apps, Backend Services, IoT Devices)     â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜- **ğŸ’¾ Idempotent Ingestion** - Duplicate event detection via idempotency keys  - Secure password hashing

                   â”‚

                   â–¼- **ğŸ”„ Database Migrations** - Alembic-managed schema versioning

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚                    FastAPI Application                       â”‚- **ğŸ“ˆ Production Ready** - Rate limiting, CORS, structured logging, health checks## Features

â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚

â”‚  â”‚   Auth API   â”‚  â”‚  Events API  â”‚  â”‚ Metrics API  â”‚      â”‚- **ğŸ§ª Comprehensive Testing** - 100% test coverage with pytest-asyncio- User registration/login (JWT)

â”‚  â”‚  (JWT/OIDC)  â”‚  â”‚   (HMAC)     â”‚  â”‚   (JWT)      â”‚      â”‚

â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚- **ğŸ³ Docker Support** - Full containerization with Docker Compose- Project creation, API key management

â”‚                                                               â”‚

â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚- Event ingestion (HMAC-signed)

â”‚  â”‚   Projects   â”‚  â”‚  WebSockets  â”‚  â”‚   Health     â”‚      â”‚

â”‚  â”‚   (CRUD)     â”‚  â”‚ (Real-time)  â”‚  â”‚   Checks     â”‚      â”‚## ğŸ“‹ Table of Contents- Event listing with filtering/pagination

â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜- Real-time metrics (WebSocket)

                   â”‚

                   â–¼- [Architecture](#-architecture)- Health/readiness endpoints

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚                    Data Layer                                â”‚- [Technology Stack](#-technology-stack)- Admin/debug endpoints

â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚

â”‚  â”‚  PostgreSQL  â”‚  â”‚    Redis     â”‚  â”‚   Alembic    â”‚      â”‚- [Getting Started](#-getting-started)- Fully containerized for local/dev/prod

â”‚  â”‚  (Primary    â”‚  â”‚  (Cache/     â”‚  â”‚  (Schema     â”‚      â”‚

â”‚  â”‚   Store)     â”‚  â”‚   Sessions)  â”‚  â”‚  Migrations) â”‚      â”‚- [API Documentation](#-api-documentation)

â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜- [Database Schema](#-database-schema)## How to Run

```

- [Security](#-security)1. **Clone the repo:**

### Component Breakdown

- [Configuration](#-configuration)  ```sh

**API Layer**

- **FastAPI**: High-performance async web framework with automatic OpenAPI documentation- [Development](#-development)  git clone https://github.com/bahagh/nimbus.git

- **Pydantic**: Runtime type validation and settings management

- **SQLAlchemy 2.0**: Async ORM with connection pooling- [Testing](#-testing)  cd nimbus

- **asyncpg**: High-performance PostgreSQL driver

- [Deployment](#-deployment)  ```

**Security Layer**

- **JWT**: Stateless authentication with access/refresh token rotation- [Performance](#-performance)2. **Configure environment:**

- **HMAC-SHA256**: Request signature verification for event ingestion

- **bcrypt**: Password hashing with configurable work factor  - Edit `.env` files in `deploy/docker/` for DB/Redis credentials

- **Rate Limiting**: Token bucket algorithm via slowapi

## ğŸ—ï¸ Architecture3. **Start services (dev):**

**Data Layer**

- **PostgreSQL**: ACID-compliant relational database with JSONB support  ```sh

- **Redis**: In-memory cache for sessions and rate limiting

- **Alembic**: Schema migration management```  docker compose -f deploy/docker/compose.dev.yml up -d --build



## ğŸ› ï¸ Technology Stackâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  ```



### Core Dependenciesâ”‚                         Client Layer                         â”‚4. **Access frontend:**

| Technology | Version | Purpose |

|------------|---------|---------|â”‚  (Web Apps, Mobile Apps, Backend Services, IoT Devices)     â”‚  - Open [http://localhost:3000](http://localhost:3000)

| **Python** | 3.12+ | Language runtime |

| **FastAPI** | 0.115+ | Web framework |â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜5. **Access backend API:**

| **SQLAlchemy** | 2.0.32+ | Async ORM |

| **asyncpg** | 0.29+ | PostgreSQL driver |                   â”‚  - Open [http://localhost:8000/docs](http://localhost:8000/docs)

| **PostgreSQL** | 15+ | Primary database |

| **Redis** | 7+ | Cache & sessions |                   â–¼

| **Alembic** | 1.13+ | Migrations |

| **Pydantic** | 2.8+ | Validation |â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”## Integration

| **PyJWT** | 2.8+ | JWT handling |

| **bcrypt** | 4.1+ | Password hashing |â”‚                    FastAPI Application                       â”‚- **API:** See `/docs` for OpenAPI spec



### Development Toolsâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚- **Frontend:** Login/register, event listing, event ingestion (HMAC), metrics dashboard

- **pytest** + **pytest-asyncio**: Async testing framework

- **mypy**: Static type checkingâ”‚  â”‚   Auth API   â”‚  â”‚  Events API  â”‚  â”‚ Metrics API  â”‚      â”‚- **Backend:** Modular, extensible, ready for cloud deployment

- **ruff**: Linting and formatting

- **httpx**: Async HTTP client for testingâ”‚  â”‚  (JWT/OIDC)  â”‚  â”‚   (HMAC)     â”‚  â”‚   (JWT)      â”‚      â”‚

- **Poetry**: Dependency management

â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚## Good Aspects

## ğŸš€ Getting Started

â”‚                                                               â”‚- Clean separation of backend/frontend

### Prerequisites

â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚- Secure authentication and event ingestion

- **Python 3.12+**

- **PostgreSQL 15+**â”‚  â”‚   Projects   â”‚  â”‚  WebSockets  â”‚  â”‚   Health     â”‚      â”‚- Real-time metrics and scalable architecture

- **Redis 7+**

- **Poetry** (for dependency management)â”‚  â”‚   (CRUD)     â”‚  â”‚ (Real-time)  â”‚  â”‚   Checks     â”‚      â”‚- Modern codebase, best practices, and robust error handling



### Installationâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚- Easy local development and deployment



1. **Clone the repository**â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```bash

git clone https://github.com/bahagh/nimbus.git                   â”‚## Contributing

cd nimbus/apps/api

```                   â–¼- Fork, branch, and PRs welcome



2. **Install dependencies**â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”- See code comments and structure for extension points

```bash

poetry installâ”‚                    Data Layer                                â”‚

```

â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚---

3. **Configure environment**

```bashâ”‚  â”‚  PostgreSQL  â”‚  â”‚    Redis     â”‚  â”‚   Alembic    â”‚      â”‚**Nimbus**: Fast, secure, and extensible event analytics for modern SaaS.

cp .env.example .env

# Edit .env with your configurationâ”‚  â”‚  (Primary    â”‚  â”‚  (Cache/     â”‚  â”‚  (Schema     â”‚      â”‚

```

â”‚  â”‚   Store)     â”‚  â”‚   Sessions)  â”‚  â”‚  Migrations) â”‚      â”‚## ğŸ› ï¸ **Technology Stack**

4. **Set up the database**

```bashâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚

# Create databases

createdb nimbusâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜### **Backend**

createdb nimbus_test

```- **FastAPI** - High-performance async web framework

# Run migrations

poetry run alembic upgrade head- **SQLAlchemy 2.0** - Modern async ORM with advanced features

```

### Component Breakdown- **PostgreSQL** - Primary database with JSONB support

5. **Start the server**

```bash- **Redis** - Caching and real-time pub/sub

poetry run uvicorn nimbus.main:app --reload --host 0.0.0.0 --port 8000

```**API Layer**- **Alembic** - Database migrations



The API will be available at `http://localhost:8000`- **FastAPI**: High-performance async web framework with automatic OpenAPI documentation

- **Interactive API Docs**: http://localhost:8000/docs

- **Alternative Docs**: http://localhost:8000/redoc- **Pydantic**: Runtime type validation and settings management### **Security**



### Docker Deployment- **SQLAlchemy 2.0**: Async ORM with connection pooling- **HMAC authentication** for ingestion endpoints



```bash- **asyncpg**: High-performance PostgreSQL driver- **JWT tokens** for API access

# From repository root

docker-compose -f nimbus/deploy/docker/compose.dev.yml up -d- **Rate limiting** with Redis backend



# Run migrations**Security Layer**- **Input validation** and sanitization

docker exec nimbus-api poetry run alembic upgrade head

```- **JWT**: Stateless authentication with access/refresh token rotation- **CORS protection** with configurable origins



## ğŸ“š API Documentation- **HMAC-SHA256**: Request signature verification for event ingestion



### Authentication- **bcrypt**: Password hashing with configurable work factor### **Observability**



#### User Registration & Login- **Rate Limiting**: Token bucket algorithm via slowapi- **Structured logging** with configurable levels

```http

POST /v1/auth/register- **Health checks** for dependencies

Content-Type: application/json

**Data Layer**- **Performance metrics** collection

{

  "email": "user@example.com",- **PostgreSQL**: ACID-compliant relational database with JSONB support- **OpenTelemetry** integration ready

  "password": "SecurePass123!"

}- **Redis**: In-memory cache for sessions and rate limiting- **Comprehensive error handling**

```

- **Alembic**: Schema migration management

#### Token Refresh

```http## ğŸš€ **Quick Start**

POST /v1/auth/refresh

Authorization: Bearer <refresh_token>## ğŸ› ï¸ Technology Stack

```

### **Prerequisites**

### Project Management

### Core Dependencies- Python 3.12+

#### Create Project

```http| Technology | Version | Purpose |- PostgreSQL 14+

POST /v1/projects

Authorization: Bearer <jwt_token>|------------|---------|---------|- Redis 7+

Content-Type: application/json

| **Python** | 3.12+ | Language runtime |- Poetry (recommended) or pip

{

  "name": "My Analytics Project"| **FastAPI** | 0.115+ | Web framework |

}

| **SQLAlchemy** | 2.0.32+ | Async ORM |### **1. Environment Setup**

Response:

{| **asyncpg** | 0.29+ | PostgreSQL driver |

  "project": {

    "id": "uuid",| **PostgreSQL** | 15+ | Primary database |```bash

    "name": "My Analytics Project",

    "api_key_id": "key_xxxxx",| **Redis** | 7+ | Cache & sessions |# Clone the repository

    "created_at": "2025-11-01T00:00:00Z"

  },| **Alembic** | 1.13+ | Migrations |git clone https://github.com/bahagh/nimbus.git

  "api_key_secret": "secret_xxxxx"  // Only shown once!

}| **Pydantic** | 2.8+ | Validation |cd nimbus

```

| **PyJWT** | 2.8+ | JWT handling |

### Event Ingestion

| **bcrypt** | 4.1+ | Password hashing |# Copy environment template

Events use **HMAC-SHA256** signature authentication:

cp apps/api/env.example apps/api/.env

```http

POST /v1/events### Development Tools

Content-Type: application/json

X-Api-Key-Id: key_xxxxx- **pytest** + **pytest-asyncio**: Async testing framework# Edit configuration (see Configuration section)

X-Api-Timestamp: 1730419200

X-Api-Signature: <hmac_sha256_hex>- **mypy**: Static type checkingnano apps/api/.env



{- **ruff**: Linting and formatting```

  "project_id": "uuid",

  "events": [- **httpx**: Async HTTP client for testing

    {

      "name": "page_view",- **Poetry**: Dependency management

      "ts": "2025-11-01T12:00:00Z",

      "props": {"page": "/home", "referrer": "google"},### **2. Database Setup**

      "user_id": "user_123",

      "idempotency_key": "evt_unique_id"## ğŸš€ Getting Started

    }

  ]```bash

}

```### Prerequisites# Start PostgreSQL and Redis (using Docker)



**HMAC Signature Calculation:**docker compose -f deploy/docker/compose.dev.yml up -d

```python

import hmac- **Python 3.12+**

import hashlib

- **PostgreSQL 15+**# Install dependencies

def create_signature(timestamp, method, path, body, secret):

    message = f"{timestamp}:{method}:{path}:{body}"- **Redis 7+**cd apps/api

    return hmac.new(

        secret.encode(),- **Poetry** (for dependency management)poetry install

        message.encode(),

        hashlib.sha256

    ).hexdigest()

```### Installation# Run database migrations



### Metrics & Analyticspoetry run alembic upgrade head



```http1. **Clone the repository**```

GET /v1/metrics?project_id=uuid&bucket=1h&limit=24

Authorization: Bearer <jwt_token>```bash



Response:git clone https://github.com/bahagh/nimbus.git#### Create test database for backend tests

{

  "metric": "events.count",cd nimbus/apps/api

  "bucket": "1h",

  "series": [```If you want to run backend tests, create a dedicated test database:

    {"ts": "2025-11-01T12:00:00Z", "value": 1523},

    {"ts": "2025-11-01T13:00:00Z", "value": 1847}

  ]

}2. **Install dependencies**1. Create database `nimbus_test` and user `postgres` with password `baha123` (use pgAdmin or psql):

```

```bash  ```sql

**Supported Buckets:** `1m`, `5m`, `15m`, `1h`, `1d`

poetry install  CREATE DATABASE nimbus_test OWNER postgres;

## ğŸ—„ï¸ Database Schema

```  GRANT ALL PRIVILEGES ON DATABASE nimbus_test TO postgres;

```sql

-- Users Table  ```

CREATE TABLE users (

    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),3. **Configure environment**2. In `.env` or `.env.example`, set:

    email VARCHAR(255) UNIQUE NOT NULL,

    hashed_password BYTEA NOT NULL,```bash  ```

    created_at TIMESTAMPTZ DEFAULT NOW(),

    updated_at TIMESTAMPTZ DEFAULT NOW()cp .env.example .env  NIMBUS_DATABASE_URL=postgresql+asyncpg://postgres:baha123@localhost:5432/nimbus_test

);

# Edit .env with your configuration  ```

-- Projects Table

CREATE TABLE projects (```

    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),

    name VARCHAR(200) NOT NULL,### **3. Start the Services**

    api_key_id VARCHAR(100) UNIQUE NOT NULL,

    api_key_hash BYTEA NOT NULL,  -- SHA-256 hash4. **Set up the database**

    created_at TIMESTAMPTZ DEFAULT NOW(),

    updated_at TIMESTAMPTZ DEFAULT NOW()```bash```bash

);

# Create databases# Terminal 1: Start API server

-- Events Table (Partitioned for scalability)

CREATE TABLE events (createdb nimbusmake dev-api

    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),

    project_id UUID NOT NULL REFERENCES projects(id) ON DELETE CASCADE,createdb nimbus_test

    name VARCHAR(200) NOT NULL,

    ts TIMESTAMP NOT NULL,# Terminal 2: Start background worker

    props JSONB NOT NULL DEFAULT '{}',

    user_id VARCHAR(200),# Run migrationsmake dev-worker

    seq INTEGER,

    idempotency_key VARCHAR(200),poetry run alembic upgrade head```

    created_at TIMESTAMPTZ DEFAULT NOW(),

    updated_at TIMESTAMPTZ DEFAULT NOW(),```

    

    -- IndexesThe API will be available at `http://localhost:8000`

    CONSTRAINT ux_events_project_seq UNIQUE (project_id, seq) 

        WHERE seq IS NOT NULL,5. **Start the server**

    CONSTRAINT ux_events_idempotency_key UNIQUE (

        project_id, name, ts, COALESCE(user_id, ''), idempotency_key```bash## ğŸš¢ Docker Compose Quick Start

    ) WHERE idempotency_key IS NOT NULL

);poetry run uvicorn nimbus.main:app --reload --host 0.0.0.0 --port 8000



-- Indexes for performance``````bash

CREATE INDEX ix_events_project_ts ON events(project_id, ts);

CREATE INDEX ix_events_project_seq ON events(project_id, seq);cd deploy/docker

```

The API will be available at `http://localhost:8000`cp .env.example .env # Edit secrets for production

## ğŸ” Security

- **Interactive API Docs**: http://localhost:8000/docscd ../..

### Authentication Methods

- **Alternative Docs**: http://localhost:8000/redoc# Build and run all services

1. **JWT (JSON Web Tokens)**

   - Used for user authentication and project management# (API, worker, DB, Redis, frontend)

   - HS256 algorithm by default

   - Configurable TTL (default: 1 hour access, 7 days refresh)### Docker Deploymentdocker compose -f deploy/docker/compose.dev.yml up --build

   - Optional OIDC/JWKS support for RS256

```

2. **HMAC Request Signing**

   - Used for event ingestion API```bash

   - SHA-256 HMAC with per-project secrets

   - Timestamp validation (5-minute window)# From repository root- The API will be at http://localhost:8000

   - Prevents replay attacks

docker-compose -f deploy/docker/compose.dev.yml up -d- The frontend will be at http://localhost:5173

3. **Password Security**

   - bcrypt hashing (configurable work factor)- DB and Redis are started with persistent volumes

   - Secure password storage

   - Email validation# Run migrations



### Security Best Practicesdocker exec nimbus-api poetry run alembic upgrade head## âš™ï¸ **Configuration**



```env```

# Strong JWT secret (minimum 32 characters)

NIMBUS_JWT_SECRET=your-super-secret-jwt-key-minimum-32-characters-long### **Environment Variables**



# Unique per-project API secrets## ğŸ“š API Documentation

# Generate with: python -c "import secrets; print(secrets.token_urlsafe(48))"

All configuration is handled through environment variables with the `NIMBUS_` prefix:

# Enable HTTPS in production

# Use environment-specific secrets### Authentication

# Rotate keys regularly

``````bash



### Rate Limiting#### User Registration & Login# Security Configuration



```python```httpNIMBUS_JWT_SECRET="your-super-secure-jwt-secret-min-32-chars"

# Default: 120 requests/minute per IP

NIMBUS_RATE_LIMIT_PER_MINUTE=120POST /v1/auth/registerNIMBUS_INGEST_API_KEY_SECRET="your-super-secure-ingest-secret"



# Event ingestion: 240 requests/minute (2x default)Content-Type: application/json

```

# Database Configuration  

## âš™ï¸ Configuration

{NIMBUS_DATABASE_URL="postgresql+asyncpg://user:pass@localhost:5432/nimbus"

### Environment Variables

  "email": "user@example.com",NIMBUS_DB_POOL_SIZE=10

```bash

# Application  "password": "SecurePass123!"NIMBUS_DB_MAX_OVERFLOW=20

NIMBUS_APP_NAME=Nimbus API

NIMBUS_ENVIRONMENT=production  # development, staging, production}

NIMBUS_LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR

```# Redis Configuration

# Database

NIMBUS_DATABASE_URL=postgresql+asyncpg://user:pass@host:5432/nimbusNIMBUS_REDIS_URL="redis://localhost:6379/0"

NIMBUS_DB_POOL_SIZE=10

NIMBUS_DB_MAX_OVERFLOW=20#### Token Refresh



# Redis```http# Security & Rate Limiting

NIMBUS_REDIS_URL=redis://localhost:6379/0

NIMBUS_REDIS_POOL_SIZE=10POST /v1/auth/refreshNIMBUS_ALLOWED_ORIGINS="http://localhost:3000,https://yourdomain.com"



# SecurityAuthorization: Bearer <refresh_token>NIMBUS_RATE_LIMIT_PER_MINUTE=1000

NIMBUS_JWT_SECRET=your-secret-key-here

NIMBUS_JWT_ALGORITHM=HS256```

NIMBUS_JWT_ACCESS_TTL_SECONDS=3600

NIMBUS_JWT_REFRESH_TTL_SECONDS=604800# Environment Settings



# API Keys (deprecated - use per-project keys)### Project ManagementNIMBUS_ENVIRONMENT="production"  # development, staging, production

NIMBUS_INGEST_API_KEY_ID=your-key-id

NIMBUS_INGEST_API_KEY_SECRET=your-secretNIMBUS_LOG_LEVEL="INFO"



# CORS#### Create Project```

NIMBUS_ALLOWED_ORIGINS=["http://localhost:3000","https://yourdomain.com"]

```http

# Rate Limiting

NIMBUS_RATE_LIMIT_ENABLED=truePOST /v1/projects### **Production Configuration**

NIMBUS_RATE_LIMIT_PER_MINUTE=120

Authorization: Bearer <jwt_token>

# Features

NIMBUS_ENABLE_METRICS=trueContent-Type: application/jsonFor production deployments:

NIMBUS_ENABLE_WEBSOCKETS=true

```



## ğŸ’» Development{1. **Generate secure secrets:**



### Project Structure  "name": "My Analytics Project"```bash



```}python -c "import secrets; print('JWT:', secrets.token_urlsafe(64))"

apps/api/

â”œâ”€â”€ src/nimbus/python -c "import secrets; print('INGEST:', secrets.token_urlsafe(64))"

â”‚   â”œâ”€â”€ models/          # SQLAlchemy models

â”‚   â”œâ”€â”€ repositories/    # Data access layerResponse:```

â”‚   â”œâ”€â”€ routes/          # API endpoints

â”‚   â”œâ”€â”€ schemas/         # Pydantic models{

â”‚   â”œâ”€â”€ security/        # Auth & crypto

â”‚   â”œâ”€â”€ services/        # Business logic  "project": {2. **Configure database connection pooling:**

â”‚   â””â”€â”€ main.py          # Application entry

â”œâ”€â”€ tests/               # Test suite    "id": "uuid",```bash

â”œâ”€â”€ alembic/             # Database migrations

â”œâ”€â”€ pyproject.toml       # Dependencies    "name": "My Analytics Project",NIMBUS_DB_POOL_SIZE=20

â””â”€â”€ Dockerfile           # Container definition

```    "api_key_id": "key_xxxxx",NIMBUS_DB_MAX_OVERFLOW=40



### Running Development Server    "created_at": "2025-11-01T00:00:00Z"NIMBUS_DB_POOL_TIMEOUT=30



```bash  },```

# With hot reload

poetry run uvicorn nimbus.main:app --reload  "api_key_secret": "secret_xxxxx"  // Only shown once!



# With custom host/port}3. **Set production-grade rate limits:**

poetry run uvicorn nimbus.main:app --host 0.0.0.0 --port 8080

``````bash

# With debug logging

LOG_LEVEL=DEBUG poetry run uvicorn nimbus.main:app --reloadNIMBUS_RATE_LIMIT_PER_MINUTE=500

```

### Event IngestionNIMBUS_ALLOWED_ORIGINS="https://yourdomain.com"

### Database Migrations

```

```bash

# Create new migrationEvents use **HMAC-SHA256** signature authentication:

poetry run alembic revision --autogenerate -m "Add new column"

## ğŸ“Š **API Documentation**

# Apply migrations

poetry run alembic upgrade head```http



# Rollback one versionPOST /v1/events### **Event Ingestion**

poetry run alembic downgrade -1

Content-Type: application/json

# Show current version

poetry run alembic currentX-Api-Key-Id: key_xxxxx**POST /v1/events** - Ingest events with HMAC authentication



# View migration historyX-Api-Timestamp: 1730419200

poetry run alembic history

```X-Api-Signature: <hmac_sha256_hex>```bash



### Code Quality# Generate HMAC signature



```bash{timestamp=$(date +%s)

# Type checking

poetry run mypy src/  "project_id": "uuid",method="POST"



# Linting  "events": [path="/v1/events"

poetry run ruff check src/

    {body='{"project_id":"uuid","events":[{"name":"page_view","ts":"2025-01-01T00:00:00Z","props":{"page":"/home"}}]}'

# Formatting

poetry run ruff format src/      "name": "page_view",

```

      "ts": "2025-11-01T12:00:00Z",# Calculate signature

## ğŸ§ª Testing

      "props": {"page": "/home", "referrer": "google"},signature=$(echo -n "${timestamp}:${method}:${path}:${body}" | openssl dgst -sha256 -hmac "your-secret" -hex | cut -d' ' -f2)

### Running Tests

      "user_id": "user_123",

```bash

# Run all tests      "idempotency_key": "evt_unique_id"# Send request

poetry run pytest

    }curl -X POST http://localhost:8000/v1/events \

# Run with coverage

poetry run pytest --cov=nimbus --cov-report=html  ]  -H "Content-Type: application/json" \



# Run specific test file}  -H "X-Api-Key-Id: your-key-id" \

poetry run pytest tests/test_events_api.py

```  -H "X-Api-Timestamp: ${timestamp}" \

# Run with verbose output

poetry run pytest -v -s  -H "X-Api-Signature: ${signature}" \



# Run only fast tests (exclude slow integration tests)**HMAC Signature Calculation:**  -d "${body}"

poetry run pytest -m "not slow"

``````python```



### Test Structureimport hmac



```pythonimport hashlib### **Event Querying**

# apps/api/tests/

â”œâ”€â”€ conftest.py              # Fixtures & configuration

â”œâ”€â”€ test_auth.py             # Authentication tests

â”œâ”€â”€ test_events_api.py       # Event ingestion testsdef create_signature(timestamp, method, path, body, secret):**GET /v1/events** - Query events with JWT authentication

â”œâ”€â”€ test_metrics_api.py      # Analytics tests

â”œâ”€â”€ test_health.py           # Health check tests    message = f"{timestamp}:{method}:{path}:{body}"

â””â”€â”€ testutils.py             # Test utilities

```    return hmac.new(```bash



### Test Coverage        secret.encode(),# Get JWT token



```        message.encode(),token=$(curl -X POST http://localhost:8000/v1/auth/login \

tests/test_api_basic.py::test_health âœ“

tests/test_api_basic.py::test_register_and_login âœ“        hashlib.sha256  -H "Content-Type: application/json" \

tests/test_api_basic.py::test_project_create âœ“

tests/test_auth.py::test_token_cycle âœ“    ).hexdigest()  -d '{"username":"demo","password":"demo123"}' | jq -r .access_token)

tests/test_events_api.py::test_ingest_event_success âœ“

tests/test_health.py::test_health âœ“```

tests/test_metrics_api.py::test_metrics_flow_after_ingest âœ“

# Query events

7 passed in 1.83s âœ…

```### Metrics & Analyticscurl -X GET "http://localhost:8000/v1/events?project_id=uuid&limit=10" \



## ğŸš¢ Deployment  -H "Authorization: Bearer ${token}"



### Docker Production Build```http```



```dockerfileGET /v1/metrics?project_id=uuid&bucket=1h&limit=24

FROM python:3.12-slim

Authorization: Bearer <jwt_token>### **Real-time Metrics**

WORKDIR /app

COPY pyproject.toml poetry.lock ./

RUN pip install poetry && poetry install --no-dev

Response:**WebSocket /ws/projects/{project_id}** - Live metrics stream

COPY . .

EXPOSE 8000{



CMD ["poetry", "run", "uvicorn", "nimbus.main:app", "--host", "0.0.0.0"]  "metric": "events.count",```javascript

```

  "bucket": "1h",const ws = new WebSocket('ws://localhost:8000/ws/projects/your-project-id');

### Docker Compose

  "series": [ws.onmessage = (event) => {

```yaml

services:    {"ts": "2025-11-01T12:00:00Z", "value": 1523},  const metrics = JSON.parse(event.data);

  api:

    build: ./apps/api    {"ts": "2025-11-01T13:00:00Z", "value": 1847}  console.log('Live metrics:', metrics);

    ports:

      - "8000:8000"  ]};

    environment:

      - DATABASE_URL=postgresql+asyncpg://postgres:password@db:5432/nimbus}```

      - REDIS_URL=redis://redis:6379/0

    depends_on:```

      - db

      - redis## ğŸ”§ **Development**



  db:**Supported Buckets:** `1m`, `5m`, `15m`, `1h`, `1d`

    image: postgres:15

    environment:### **Running Tests**

      POSTGRES_PASSWORD: password

      POSTGRES_DB: nimbus## ğŸ—„ï¸ Database Schema



  redis:```bash

    image: redis:7

``````sql# Run all tests



### Health Checks-- Users Tablemake test



```bashCREATE TABLE users (

# Basic health

curl http://localhost:8000/health    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),# Run with coverage



# Database connectivity    email VARCHAR(255) UNIQUE NOT NULL,poetry run pytest --cov=nimbus --cov-report=html

curl http://localhost:8000/v1/health

```    hashed_password BYTEA NOT NULL,



## ğŸ“Š Performance    created_at TIMESTAMPTZ DEFAULT NOW(),# Run specific test file



### Benchmarks    updated_at TIMESTAMPTZ DEFAULT NOW()poetry run pytest tests/test_events_api.py -v



- **Event Ingestion**: 10,000+ events/second on 4-core machine);```

- **Query Latency**: <50ms for aggregated metrics (1M events)

- **Concurrent Connections**: 1000+ via async connection pooling



### Optimization Tips-- Projects Table### **Code Quality**



1. **Database Indexing**CREATE TABLE projects (

   - Compound indexes on `(project_id, ts)` for time-series queries

   - Partial indexes for idempotency checks    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),```bash



2. **Connection Pooling**    name VARCHAR(200) NOT NULL,# Linting

   ```python

   # Tune for your workload    api_key_id VARCHAR(100) UNIQUE NOT NULL,make lint

   NIMBUS_DB_POOL_SIZE=20

   NIMBUS_DB_MAX_OVERFLOW=40    api_key_hash BYTEA NOT NULL,  -- SHA-256 hash

   ```

    created_at TIMESTAMPTZ DEFAULT NOW(),# Type checking  

3. **Caching Strategy**

   - Redis for session storage    updated_at TIMESTAMPTZ DEFAULT NOW()make typecheck

   - Query result caching for repeated analytics

);

4. **Batch Processing**

   - Bulk insert events (up to 1000 per request)# Format code

   - Async task queue for heavy computations

-- Events Table (Partitioned for scalability)poetry run black .

## ğŸ“„ License

CREATE TABLE events (poetry run isort .

This project is licensed under the MIT License.

    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),```

## ğŸ‘¥ Author

    project_id UUID NOT NULL REFERENCES projects(id) ON DELETE CASCADE,

**Baha Ghrissi** - [bahagh](https://github.com/bahagh)

    name VARCHAR(200) NOT NULL,### **Database Migrations**

## ğŸ™ Acknowledgments

    ts TIMESTAMP NOT NULL,

- FastAPI for the excellent async web framework

- SQLAlchemy team for the powerful ORM    props JSONB NOT NULL DEFAULT '{}',```bash

- PostgreSQL community for the robust database

    user_id VARCHAR(200),# Create new migration

## ğŸ“ Support

    seq INTEGER,poetry run alembic revision --autogenerate -m "description"

- **Issues**: [GitHub Issues](https://github.com/bahagh/nimbus/issues)

- **Email**: baha.ghrissi@esprit.tn    idempotency_key VARCHAR(200),



## ğŸ—ºï¸ Roadmap    created_at TIMESTAMPTZ DEFAULT NOW(),# Apply migrations



- [ ] Frontend dashboard (React + TypeScript) - **In Progress**    updated_at TIMESTAMPTZ DEFAULT NOW(),poetry run alembic upgrade head

- [ ] GraphQL API support

- [ ] Multi-region deployment    

- [ ] Advanced analytics (funnels, retention, cohorts)

- [ ] Export to data warehouses (BigQuery, Snowflake)    -- Indexes# Rollback migration

- [ ] Real-time alerting system

- [ ] Mobile SDKs (iOS, Android)    CONSTRAINT ux_events_project_seq UNIQUE (project_id, seq) poetry run alembic downgrade -1



---        WHERE seq IS NOT NULL,```



**Built with â¤ï¸ using FastAPI**    CONSTRAINT ux_events_idempotency_key UNIQUE (


        project_id, name, ts, COALESCE(user_id, ''), idempotency_key## ğŸš¢ **Deployment**

    ) WHERE idempotency_key IS NOT NULL

);### **Docker Deployment**



-- Indexes for performance```bash

CREATE INDEX ix_events_project_ts ON events(project_id, ts);# Build images

CREATE INDEX ix_events_project_seq ON events(project_id, seq);docker build -t nimbus-api apps/api/

```docker build -t nimbus-worker apps/worker/



## ğŸ” Security# Run with docker-compose

docker compose -f deploy/docker/compose.prod.yml up -d

### Authentication Methods```



1. **JWT (JSON Web Tokens)**### **Kubernetes Deployment**

   - Used for user authentication and project management

   - HS256 algorithm by default```yaml

   - Configurable TTL (default: 1 hour access, 7 days refresh)apiVersion: apps/v1

   - Optional OIDC/JWKS support for RS256kind: Deployment

metadata:

2. **HMAC Request Signing**  name: nimbus-api

   - Used for event ingestion APIspec:

   - SHA-256 HMAC with per-project secrets  replicas: 3

   - Timestamp validation (5-minute window)  selector:

   - Prevents replay attacks    matchLabels:

      app: nimbus-api

3. **Password Security**  template:

   - bcrypt hashing (configurable work factor)    metadata:

   - Secure password storage      labels:

   - Email validation        app: nimbus-api

    spec:

### Security Best Practices      containers:

      - name: api

```env        image: nimbus-api:latest

# Strong JWT secret (minimum 32 characters)        ports:

NIMBUS_JWT_SECRET=your-super-secret-jwt-key-minimum-32-characters-long        - containerPort: 8000

        env:

# Unique per-project API secrets        - name: NIMBUS_DATABASE_URL

# Generate with: python -c "import secrets; print(secrets.token_urlsafe(48))"          valueFrom:

            secretKeyRef:

# Enable HTTPS in production              name: nimbus-secrets

# Use environment-specific secrets              key: database-url

# Rotate keys regularly        livenessProbe:

```          httpGet:

            path: /health

### Rate Limiting            port: 8000

        readinessProbe:

```python          httpGet:

# Default: 120 requests/minute per IP            path: /readiness

NIMBUS_RATE_LIMIT_PER_MINUTE=120            port: 8000

```

# Event ingestion: 240 requests/minute (2x default)

```## ğŸ“ˆ **Performance Tuning**



## âš™ï¸ Configuration### **Database Optimization**



### Environment VariablesThe system includes performance optimizations:



```bash- **Strategic indexes** for common query patterns

# Application- **Connection pooling** with configurable limits

NIMBUS_APP_NAME=Nimbus API- **Partial indexes** for frequently accessed recent data

NIMBUS_ENVIRONMENT=production  # development, staging, production- **GIN indexes** for JSON property searches

NIMBUS_LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR- **Constraint checks** for data integrity



# Database### **Application Performance**

NIMBUS_DATABASE_URL=postgresql+asyncpg://user:pass@host:5432/nimbus

NIMBUS_DB_POOL_SIZE=10- **Async processing** throughout the stack

NIMBUS_DB_MAX_OVERFLOW=20- **Connection reuse** with keep-alive

- **Rate limiting** to prevent abuse

# Redis- **Batch processing** for high-volume ingestion

NIMBUS_REDIS_URL=redis://localhost:6379/0- **Background workers** for heavy operations

NIMBUS_REDIS_POOL_SIZE=10

## ğŸ”’ **Security Best Practices**

# Security

NIMBUS_JWT_SECRET=your-secret-key-here### **Authentication & Authorization**

NIMBUS_JWT_ALGORITHM=HS256- Per-project API keys with HMAC signatures

NIMBUS_JWT_ACCESS_TTL_SECONDS=3600- JWT tokens with configurable expiration

NIMBUS_JWT_REFRESH_TTL_SECONDS=604800- Input validation and sanitization

- Rate limiting per client

# API Keys (deprecated - use per-project keys)

NIMBUS_INGEST_API_KEY_ID=your-key-id### **Data Protection**

NIMBUS_INGEST_API_KEY_SECRET=your-secret- Encrypted connections (TLS/SSL)

- Secure secret management

# CORS- SQL injection prevention

NIMBUS_ALLOWED_ORIGINS=["http://localhost:3000","https://yourdomain.com"]- XSS protection



# Rate Limiting## ğŸ“Š **Monitoring & Observability**

NIMBUS_RATE_LIMIT_ENABLED=true

NIMBUS_RATE_LIMIT_PER_MINUTE=120### **Health Checks**

- `/health` - Basic service health

# Features- `/health/detailed` - Comprehensive dependency checks

NIMBUS_ENABLE_METRICS=true- `/readiness` - Kubernetes readiness probe

NIMBUS_ENABLE_WEBSOCKETS=true

```### **Metrics Collection**

- Request/response metrics

## ğŸ’» Development- Database connection pool stats

- Rate limiting metrics

### Project Structure- Error rates and latency



```### **Logging**

apps/api/- Structured JSON logging

â”œâ”€â”€ src/nimbus/- Configurable log levels

â”‚   â”œâ”€â”€ models/          # SQLAlchemy models- Request correlation IDs

â”‚   â”œâ”€â”€ repositories/    # Data access layer- Performance logging

â”‚   â”œâ”€â”€ routes/          # API endpoints

â”‚   â”œâ”€â”€ schemas/         # Pydantic models## ğŸ¤ **Contributing**

â”‚   â”œâ”€â”€ security/        # Auth & crypto

â”‚   â”œâ”€â”€ services/        # Business logic1. Fork the repository

â”‚   â””â”€â”€ main.py          # Application entry2. Create a feature branch

â”œâ”€â”€ tests/               # Test suite3. Make your changes

â”œâ”€â”€ alembic/             # Database migrations4. Add tests for new functionality

â”œâ”€â”€ pyproject.toml       # Dependencies5. Ensure all tests pass

â””â”€â”€ Dockerfile           # Container definition6. Submit a pull request

```

## ğŸ“„ **License**

### Running Development Server

This project is licensed under the MIT License - see the LICENSE file for details.

```bash

# With hot reload

poetry run uvicorn nimbus.main:app --reload


# With custom host/port
poetry run uvicorn nimbus.main:app --host 0.0.0.0 --port 8080

# With debug logging
LOG_LEVEL=DEBUG poetry run uvicorn nimbus.main:app --reload
```

### Database Migrations

```bash
# Create new migration
poetry run alembic revision --autogenerate -m "Add new column"

# Apply migrations
poetry run alembic upgrade head

# Rollback one version
poetry run alembic downgrade -1

# Show current version
poetry run alembic current

# View migration history
poetry run alembic history
```

### Code Quality

```bash
# Type checking
poetry run mypy src/

# Linting
poetry run ruff check src/

# Formatting
poetry run ruff format src/
```

## ğŸ§ª Testing

### Running Tests

```bash
# Run all tests
poetry run pytest

# Run with coverage
poetry run pytest --cov=nimbus --cov-report=html

# Run specific test file
poetry run pytest tests/test_events_api.py

# Run with verbose output
poetry run pytest -v -s

# Run only fast tests (exclude slow integration tests)
poetry run pytest -m "not slow"
```

### Test Structure

```python
# apps/api/tests/
â”œâ”€â”€ conftest.py              # Fixtures & configuration
â”œâ”€â”€ test_auth.py             # Authentication tests
â”œâ”€â”€ test_events_api.py       # Event ingestion tests
â”œâ”€â”€ test_metrics_api.py      # Analytics tests
â”œâ”€â”€ test_health.py           # Health check tests
â””â”€â”€ testutils.py             # Test utilities
```

### Test Coverage

```
tests/test_api_basic.py::test_health âœ“
tests/test_api_basic.py::test_register_and_login âœ“
tests/test_api_basic.py::test_project_create âœ“
tests/test_auth.py::test_token_cycle âœ“
tests/test_events_api.py::test_ingest_event_success âœ“
tests/test_health.py::test_health âœ“
tests/test_metrics_api.py::test_metrics_flow_after_ingest âœ“

7 passed in 1.83s âœ…
```

## ğŸš¢ Deployment

### Docker Production Build

```dockerfile
FROM python:3.12-slim

WORKDIR /app
COPY pyproject.toml poetry.lock ./
RUN pip install poetry && poetry install --no-dev

COPY . .
EXPOSE 8000

CMD ["poetry", "run", "uvicorn", "nimbus.main:app", "--host", "0.0.0.0"]
```

### Docker Compose

```yaml
services:
  api:
    build: ./apps/api
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql+asyncpg://postgres:password@db:5432/nimbus
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - db
      - redis

  db:
    image: postgres:15
    environment:
      POSTGRES_PASSWORD: password
      POSTGRES_DB: nimbus

  redis:
    image: redis:7
```

### Health Checks

```bash
# Basic health
curl http://localhost:8000/health

# Database connectivity
curl http://localhost:8000/v1/health
```

## ğŸ“Š Performance

### Benchmarks

- **Event Ingestion**: 10,000+ events/second on 4-core machine
- **Query Latency**: <50ms for aggregated metrics (1M events)
- **Concurrent Connections**: 1000+ via async connection pooling

### Optimization Tips

1. **Database Indexing**
   - Compound indexes on `(project_id, ts)` for time-series queries
   - Partial indexes for idempotency checks

2. **Connection Pooling**
   ```python
   # Tune for your workload
   NIMBUS_DB_POOL_SIZE=20
   NIMBUS_DB_MAX_OVERFLOW=40
   ```

3. **Caching Strategy**
   - Redis for session storage
   - Query result caching for repeated analytics

4. **Batch Processing**
   - Bulk insert events (up to 1000 per request)
   - Async task queue for heavy computations

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ‘¥ Author

**Baha Ghrissi** - [bahagh](https://github.com/bahagh)

## ğŸ™ Acknowledgments

- FastAPI for the excellent async web framework
- SQLAlchemy team for the powerful ORM
- PostgreSQL community for the robust database

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/bahagh/nimbus/issues)
- **Email**: baha.ghrissi@esprit.tn

## ğŸ—ºï¸ Roadmap

- [ ] Frontend dashboard (React + TypeScript) - **In Progress**
- [ ] GraphQL API support
- [ ] Multi-region deployment
- [ ] Advanced analytics (funnels, retention, cohorts)
- [ ] Export to data warehouses (BigQuery, Snowflake)
- [ ] Real-time alerting system
- [ ] Mobile SDKs (iOS, Android)

---

**Built with â¤ï¸ using FastAPI**
